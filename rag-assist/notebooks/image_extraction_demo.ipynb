{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PPT Content Extraction Demo - 2-Step Framework\n",
    "\n",
    "This notebook demonstrates the 2-step framework for extracting and embedding content from PowerPoint presentations.\n",
    "\n",
    "**Step 1 (PPT Path):** Parse PPTX directly → Extract text → Generate embeddings\n",
    "**Step 2 (PDF Path):** Parse PDF version → Extract text + images → Generate embeddings\n",
    "\n",
    "**Key Features:**\n",
    "- Text extraction from **both** PPT and PDF for redundancy\n",
    "- Duplicate text between PPT and PDF is detected and skipped\n",
    "- Images from PDF are linked to text by slide_number/page_number\n",
    "- If image extraction fails, text is still retrievable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "**Edit these values for your environment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these values\n",
    "# =============================================================================\n",
    "\n",
    "# S3 bucket for storing extracted images\n",
    "S3_BUCKET = \"your-bucket-name\"  # <-- Edit this\n",
    "\n",
    "# S3 prefix (folder path) for images\n",
    "S3_PREFIX = \"images/ppt/\"  # <-- Edit if needed\n",
    "\n",
    "# Path to your PowerPoint file\n",
    "PPTX_PATH = \"./sample_presentation.pptx\"  # <-- Edit this\n",
    "\n",
    "# Path to your PDF file (manually converted from PPT)\n",
    "PDF_PATH = \"./sample_presentation.pdf\"  # <-- Edit this\n",
    "\n",
    "# Image quality (DPI - higher = better quality, larger files)\n",
    "DPI = 150  # Recommended: 150 for web, 300 for print\n",
    "\n",
    "# OpenSearch configuration (if using full pipeline)\n",
    "OPENSEARCH_HOST = \"your-opensearch-endpoint\"  # <-- Edit this\n",
    "OPENSEARCH_INDEX = \"ppt-content\"\n",
    "\n",
    "# =============================================================================\n",
    "print(f\"S3 Bucket: {S3_BUCKET}\")\n",
    "print(f\"S3 Prefix: {S3_PREFIX}\")\n",
    "print(f\"PPTX Path: {PPTX_PATH}\")\n",
    "print(f\"PDF Path: {PDF_PATH}\")\n",
    "print(f\"DPI: {DPI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if dependencies are not installed\n",
    "# !pip install python-pptx PyMuPDF Pillow boto3 opensearch-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path if running from notebooks directory\n",
    "src_path = Path(\"../src\").resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the extraction modules\n",
    "from rag_assist.ingestion.images import (\n",
    "    # Data models\n",
    "    SlideTextContent,\n",
    "    PPTExtractionResult,\n",
    "    PDFPageContent,\n",
    "    PDFExtractionResult,\n",
    "    # Extractors\n",
    "    PPTXTextExtractor,\n",
    "    PDFContentExtractor,\n",
    "    # Deduplication\n",
    "    TextDeduplicator,\n",
    "    # S3 storage\n",
    "    S3ImageStore,\n",
    "    # Embedders (optional - requires Bedrock)\n",
    "    # CohereTextEmbedder,\n",
    "    # TitanMultimodalEmbedder,\n",
    ")\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 4. Step 1: Extract Text from PPTX\n",
    "\n",
    "Extract text content from all slides using python-pptx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PPT text extractor\n",
    "ppt_extractor = PPTXTextExtractor(\n",
    "    include_speaker_notes=True,\n",
    "    include_tables=True,\n",
    "    detect_visual_content=True,\n",
    ")\n",
    "\n",
    "# Extract text from PPTX\n",
    "pptx_path = Path(PPTX_PATH)\n",
    "if not pptx_path.exists():\n",
    "    print(f\"ERROR: File not found: {pptx_path}\")\n",
    "    print(\"Please update PPTX_PATH in Cell 2 to point to a valid .pptx file\")\n",
    "    ppt_result = None\n",
    "else:\n",
    "    ppt_result = ppt_extractor.extract(PPTX_PATH)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"STEP 1: PPT TEXT EXTRACTION RESULT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Document ID: {ppt_result.document_id}\")\n",
    "    print(f\"Filename: {ppt_result.filename}\")\n",
    "    print(f\"Total slides: {ppt_result.total_slides}\")\n",
    "    print(f\"Slides extracted: {ppt_result.slide_count}\")\n",
    "    print(f\"Slides with visual content: {ppt_result.slides_with_visuals}\")\n",
    "    print(f\"Errors: {len(ppt_result.errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted text from each slide\n",
    "if ppt_result:\n",
    "    print(\"\\nExtracted Slides:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for slide in ppt_result.slides:\n",
    "        print(f\"\\n--- Slide {slide.slide_number} ---\")\n",
    "        print(f\"Title: {slide.title or '(no title)'}\")\n",
    "        print(f\"Has visual content: {slide.has_visual_content}\")\n",
    "        print(f\"Body text preview: {slide.body_text[:200]}...\" if len(slide.body_text) > 200 else f\"Body text: {slide.body_text}\")\n",
    "        if slide.speaker_notes:\n",
    "            print(f\"Speaker notes: {slide.speaker_notes[:100]}...\")\n",
    "        if slide.tables:\n",
    "            print(f\"Tables: {len(slide.tables)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Step 2: Extract Content from PDF\n",
    "\n",
    "Extract both text AND images from the PDF version of the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PDF content extractor\n",
    "pdf_extractor = PDFContentExtractor(dpi=DPI)\n",
    "\n",
    "# Extract content from PDF\n",
    "pdf_path = Path(PDF_PATH)\n",
    "if not pdf_path.exists():\n",
    "    print(f\"ERROR: File not found: {pdf_path}\")\n",
    "    print(\"Please update PDF_PATH in Cell 2 to point to a valid .pdf file\")\n",
    "    pdf_result = None\n",
    "else:\n",
    "    # Use same document_id as PPT for linking\n",
    "    document_id = ppt_result.document_id if ppt_result else None\n",
    "    pdf_result = pdf_extractor.extract(PDF_PATH, document_id=document_id)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"STEP 2: PDF CONTENT EXTRACTION RESULT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Document ID: {pdf_result.document_id}\")\n",
    "    print(f\"Filename: {pdf_result.filename}\")\n",
    "    print(f\"Total pages: {pdf_result.total_pages}\")\n",
    "    print(f\"Pages extracted: {pdf_result.page_count}\")\n",
    "    print(f\"Pages with images: {pdf_result.pages_with_images}\")\n",
    "    print(f\"Errors: {len(pdf_result.errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview extracted PDF pages (text + images)\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "if pdf_result:\n",
    "    print(\"\\nExtracted PDF Pages:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for page in pdf_result.pages[:3]:  # Show first 3 pages\n",
    "        print(f\"\\n--- Page {page.page_number} ---\")\n",
    "        print(f\"Text length: {len(page.text_content)} chars\")\n",
    "        print(f\"Text preview: {page.text_content[:200]}...\" if len(page.text_content) > 200 else f\"Text: {page.text_content}\")\n",
    "        print(f\"Image size: {page.width_px}x{page.height_px} px ({page.size_bytes / 1024:.1f} KB)\")\n",
    "        \n",
    "        if page.has_image:\n",
    "            display(IPImage(data=page.image_bytes, width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Text Deduplication\n",
    "\n",
    "Compare PPT text with PDF text and identify duplicates to avoid indexing the same content twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ppt_result and pdf_result:\n",
    "    # Initialize deduplicator\n",
    "    deduplicator = TextDeduplicator(similarity_threshold=0.85)\n",
    "    \n",
    "    # Find duplicates\n",
    "    duplicates = deduplicator.find_duplicates(ppt_result.slides, pdf_result.pages)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DEDUPLICATION ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\n{'Slide/Page':<12} {'PPT Len':<10} {'PDF Len':<10} {'Similarity':<12} {'Duplicate?'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for dup in duplicates:\n",
    "        print(\n",
    "            f\"{dup.slide_number:<12} \"\n",
    "            f\"{dup.ppt_text_length:<10} \"\n",
    "            f\"{dup.pdf_text_length:<10} \"\n",
    "            f\"{dup.similarity_score:.2%:<12} \"\n",
    "            f\"{'Yes' if dup.is_duplicate else 'No'}\"\n",
    "        )\n",
    "    \n",
    "    # Get unique PDF text\n",
    "    unique_pdf_text = deduplicator.get_unique_pdf_text(ppt_result.slides, pdf_result.pages)\n",
    "    \n",
    "    print(f\"\\n\\nSummary:\")\n",
    "    print(f\"  Total PPT slides: {len(ppt_result.slides)}\")\n",
    "    print(f\"  Total PDF pages: {len(pdf_result.pages)}\")\n",
    "    print(f\"  Duplicate pages: {sum(1 for d in duplicates if d.is_duplicate)}\")\n",
    "    print(f\"  Unique PDF text pages: {len(unique_pdf_text)}\")\n",
    "else:\n",
    "    print(\"Missing PPT or PDF result. Run extraction cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Upload Images to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_result:\n",
    "    # Initialize S3 store\n",
    "    s3_store = S3ImageStore(\n",
    "        bucket=S3_BUCKET,\n",
    "        prefix=S3_PREFIX,\n",
    "    )\n",
    "    \n",
    "    # Upload images from all PDF pages\n",
    "    print(\"\\nUploading images to S3...\")\n",
    "    \n",
    "    s3_uris = []\n",
    "    for page in pdf_result.pages:\n",
    "        if not page.has_image:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            uri = s3_store.upload(\n",
    "                page.image_bytes,\n",
    "                document_id=page.document_id,\n",
    "                page_number=page.page_number,\n",
    "            )\n",
    "            page.s3_uri = uri\n",
    "            s3_uris.append(uri)\n",
    "            print(f\"Page {page.page_number}: {uri}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Page {page.page_number}: FAILED - {e}\")\n",
    "    \n",
    "    print(f\"\\nUploaded {len(s3_uris)} images to S3\")\n",
    "else:\n",
    "    print(\"No PDF result available. Run PDF extraction first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8. Generate Presigned URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdf_result and s3_uris:\n",
    "    print(\"\\nPresigned URLs (valid for 1 hour):\")\n",
    "    \n",
    "    for page in pdf_result.pages:\n",
    "        if page.s3_uri:\n",
    "            try:\n",
    "                presigned_url = s3_store.get_presigned_url(page.s3_uri, expiration=3600)\n",
    "                print(f\"\\nPage {page.page_number}:\")\n",
    "                print(f\"  S3 URI: {page.s3_uri}\")\n",
    "                print(f\"  URL: {presigned_url[:100]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Page {page.page_number}: Error - {e}\")\n",
    "else:\n",
    "    print(\"No S3 URIs available. Run upload cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. Generate Embeddings (Optional)\n",
    "\n",
    "Generate embeddings using Amazon Bedrock (requires AWS credentials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to generate embeddings\n",
    "# Requires: AWS credentials with Bedrock access\n",
    "\n",
    "# from rag_assist.ingestion.images import CohereTextEmbedder, TitanMultimodalEmbedder\n",
    "\n",
    "# # Initialize embedders\n",
    "# text_embedder = CohereTextEmbedder()\n",
    "# image_embedder = TitanMultimodalEmbedder()\n",
    "\n",
    "# # Generate text embeddings for PPT slides\n",
    "# if ppt_result:\n",
    "#     print(\"Generating text embeddings...\")\n",
    "#     for slide in ppt_result.slides[:3]:  # First 3 for demo\n",
    "#         embedding = text_embedder.embed(slide.full_text)\n",
    "#         print(f\"Slide {slide.slide_number}: {len(embedding)} dimensions\")\n",
    "\n",
    "# # Generate image embeddings for PDF pages\n",
    "# if pdf_result:\n",
    "#     print(\"\\nGenerating image embeddings...\")\n",
    "#     for page in pdf_result.pages[:3]:  # First 3 for demo\n",
    "#         if page.has_image:\n",
    "#             embedding = image_embedder.embed_image(page.image_bytes)\n",
    "#             print(f\"Page {page.page_number}: {len(embedding)} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 10. Full Indexing Pipeline (Optional)\n",
    "\n",
    "Index content to OpenSearch using the full pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run full indexing pipeline\n",
    "# Requires: OpenSearch cluster, AWS credentials with Bedrock access\n",
    "\n",
    "# from opensearchpy import OpenSearch\n",
    "# from rag_assist.ingestion.images import (\n",
    "#     PPTContentIndexer,\n",
    "#     CohereTextEmbedder,\n",
    "#     TitanMultimodalEmbedder,\n",
    "#     S3ImageStore,\n",
    "# )\n",
    "\n",
    "# # Initialize OpenSearch client\n",
    "# opensearch_client = OpenSearch(\n",
    "#     hosts=[{'host': OPENSEARCH_HOST, 'port': 443}],\n",
    "#     http_compress=True,\n",
    "#     use_ssl=True,\n",
    "# )\n",
    "\n",
    "# # Initialize components\n",
    "# text_embedder = CohereTextEmbedder()\n",
    "# image_embedder = TitanMultimodalEmbedder()\n",
    "# s3_store = S3ImageStore(bucket=S3_BUCKET, prefix=S3_PREFIX)\n",
    "\n",
    "# # Initialize indexer\n",
    "# indexer = PPTContentIndexer(\n",
    "#     opensearch_client=opensearch_client,\n",
    "#     text_embedder=text_embedder,\n",
    "#     image_embedder=image_embedder,\n",
    "#     s3_store=s3_store,\n",
    "#     index_name=OPENSEARCH_INDEX,\n",
    "# )\n",
    "\n",
    "# # Ensure index exists\n",
    "# indexer.ensure_index_exists()\n",
    "\n",
    "# # Run full pipeline\n",
    "# ppt_result, pdf_result = indexer.index_full_pipeline(PPTX_PATH, PDF_PATH)\n",
    "\n",
    "# print(f\"\\nIndexing Results:\")\n",
    "# print(f\"  PPT text indexed: {ppt_result.text_documents_indexed}\")\n",
    "# print(f\"  PDF text indexed: {pdf_result.text_documents_indexed}\")\n",
    "# print(f\"  PDF images indexed: {pdf_result.image_documents_indexed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 11. Search and Retrieve (Optional)\n",
    "\n",
    "Search for content and retrieve linked images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to search content\n",
    "# Requires: Completed indexing (Cell 22)\n",
    "\n",
    "# from rag_assist.ingestion.images import PPTContentRetriever\n",
    "\n",
    "# # Initialize retriever\n",
    "# retriever = PPTContentRetriever(\n",
    "#     opensearch_client=opensearch_client,\n",
    "#     text_embedder=text_embedder,\n",
    "#     s3_store=s3_store,\n",
    "#     index_name=OPENSEARCH_INDEX,\n",
    "# )\n",
    "\n",
    "# # Search for content\n",
    "# query = \"What is the architecture?\"\n",
    "# results = retriever.search(query, top_k=5, include_images=True)\n",
    "\n",
    "# print(f\"\\nSearch Results for: '{query}'\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# for r in results:\n",
    "#     print(f\"\\nSlide {r.slide_number} (score: {r.text_score:.3f})\")\n",
    "#     print(f\"Title: {r.title}\")\n",
    "#     print(f\"Text: {r.text_content[:200]}...\")\n",
    "#     if r.image_presigned_url:\n",
    "#         print(f\"Image: {r.image_presigned_url[:80]}...\")\n",
    "#         # display(IPImage(url=r.image_presigned_url, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 12. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete uploaded images from S3\n",
    "# WARNING: This will delete all images for this document from S3!\n",
    "\n",
    "# if pdf_result:\n",
    "#     doc_id = pdf_result.document_id\n",
    "#     deleted = s3_store.delete_document_images(doc_id)\n",
    "#     print(f\"Deleted {deleted} images from S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated the 2-step framework for PPT content extraction:\n",
    "\n",
    "| Step | Component | Description |\n",
    "|------|-----------|-------------|\n",
    "| 1 | `PPTXTextExtractor` | Extract text from PPTX (primary text source) |\n",
    "| 2 | `PDFContentExtractor` | Extract text + images from PDF |\n",
    "| - | `TextDeduplicator` | Detect duplicate text between PPT and PDF |\n",
    "| - | `S3ImageStore` | Upload images to S3, generate presigned URLs |\n",
    "| - | `CohereTextEmbedder` | Generate text embeddings via Bedrock |\n",
    "| - | `TitanMultimodalEmbedder` | Generate image embeddings via Bedrock |\n",
    "| - | `PPTContentIndexer` | Index to OpenSearch |\n",
    "| - | `PPTContentRetriever` | Search and retrieve with linked images |\n",
    "\n",
    "### Integration with RAG\n",
    "\n",
    "```python\n",
    "# During retrieval, get text + linked image:\n",
    "results = retriever.search(query, include_images=True)\n",
    "\n",
    "for result in results:\n",
    "    # Text content (from PPT or unique PDF text)\n",
    "    context = result.text_content\n",
    "    \n",
    "    # Linked image (if available)\n",
    "    if result.image_presigned_url:\n",
    "        # Include image in response\n",
    "        image_url = result.image_presigned_url\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
