{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPTX Image Extraction Demo\n",
    "\n",
    "This notebook demonstrates the image extraction module for extracting SmartArt, charts, and images from PowerPoint presentations.\n",
    "\n",
    "**Features:**\n",
    "- Detect slides with visual content (SmartArt, pictures, charts)\n",
    "- Render slides as PNG images\n",
    "- Upload to S3 with structured paths\n",
    "- Store mappings in OpenSearch for retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "**Edit these values for your environment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Edit these values\n",
    "# =============================================================================\n",
    "\n",
    "# S3 bucket for storing extracted images\n",
    "S3_BUCKET = \"your-bucket-name\"  # <-- Edit this\n",
    "\n",
    "# S3 prefix (folder path) for images\n",
    "S3_PREFIX = \"images/pptx/\"  # <-- Edit if needed\n",
    "\n",
    "# Path to your PowerPoint file\n",
    "PPTX_PATH = \"./sample_presentation.pptx\"  # <-- Edit this\n",
    "\n",
    "# OpenSearch endpoint (optional - for storing mappings)\n",
    "OPENSEARCH_ENDPOINT = None  # <-- Set if you want to store mappings\n",
    "\n",
    "# =============================================================================\n",
    "print(f\"S3 Bucket: {S3_BUCKET}\")\n",
    "print(f\"S3 Prefix: {S3_PREFIX}\")\n",
    "print(f\"PPTX Path: {PPTX_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on SageMaker or fresh environment\n",
    "# !pip install python-pptx Pillow structlog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path if running from notebooks directory\n",
    "src_path = Path(\"../src\").resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the image extraction module\n",
    "from rag_assist.ingestion.images import (\n",
    "    PPTXImageDetector,\n",
    "    PPTXImageExtractor,\n",
    "    S3ImageStore,\n",
    "    ImageMapper,\n",
    "    extract_images_from_pptx,\n",
    "    ImageInfo,\n",
    "    SlideImageMapping,\n",
    "    ExtractionResult,\n",
    ")\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Inspect PPTX File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "\n",
    "# Load presentation\n",
    "pptx_path = Path(PPTX_PATH)\n",
    "if not pptx_path.exists():\n",
    "    print(f\"ERROR: File not found: {pptx_path}\")\n",
    "    print(\"Please update PPTX_PATH in Cell 1 to point to a valid .pptx file\")\n",
    "else:\n",
    "    prs = Presentation(str(pptx_path))\n",
    "    print(f\"File: {pptx_path.name}\")\n",
    "    print(f\"Total slides: {len(prs.slides)}\")\n",
    "    print(f\"File size: {pptx_path.stat().st_size / 1024:.1f} KB\")\n",
    "    print(\"\\nSlide titles:\")\n",
    "    for i, slide in enumerate(prs.slides, 1):\n",
    "        title = \"\"\n",
    "        if slide.shapes.title and slide.shapes.title.has_text_frame:\n",
    "            title = slide.shapes.title.text[:50]\n",
    "        print(f\"  Slide {i}: {title or '(no title)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detect Slides with Visual Content\n",
    "\n",
    "The detector identifies slides containing:\n",
    "- **Pictures**: Embedded images\n",
    "- **SmartArt**: Diagrams and flowcharts\n",
    "- **Charts**: Data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = PPTXImageDetector(\n",
    "    include_pictures=True,\n",
    "    include_smartart=True,\n",
    "    include_charts=True,\n",
    ")\n",
    "\n",
    "# Detect slides with images\n",
    "slide_mappings = detector.detect_image_slides(PPTX_PATH)\n",
    "\n",
    "print(f\"\\nFound {len(slide_mappings)} slides with visual content:\\n\")\n",
    "print(f\"{'Slide':<8} {'Title':<30} {'Pictures':<10} {'SmartArt':<10} {'Charts':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for mapping in slide_mappings:\n",
    "    title = mapping.slide_title[:28] + \"..\" if len(mapping.slide_title) > 30 else mapping.slide_title\n",
    "    print(\n",
    "        f\"{mapping.slide_number:<8} \"\n",
    "        f\"{title:<30} \"\n",
    "        f\"{'Yes' if mapping.has_pictures else '-':<10} \"\n",
    "        f\"{'Yes' if mapping.has_smartart else '-':<10} \"\n",
    "        f\"{'Yes' if mapping.has_charts else '-':<10}\"\n",
    "    )\n",
    "\n",
    "# Get just the slide numbers\n",
    "slide_numbers = detector.get_slide_numbers_with_images(PPTX_PATH)\n",
    "print(f\"\\nSlide numbers with images: {slide_numbers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract and Preview Images\n",
    "\n",
    "Extract images from detected slides. The extractor:\n",
    "1. Tries LibreOffice rendering (most accurate for SmartArt)\n",
    "2. Falls back to extracting embedded images\n",
    "3. Creates placeholder if extraction fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image as IPImage\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = PPTXImageExtractor(\n",
    "    output_format=\"png\",\n",
    "    use_libreoffice=True,  # Set to False if LibreOffice not installed\n",
    "    fallback_to_placeholder=True,\n",
    ")\n",
    "\n",
    "# Extract images from detected slides\n",
    "extracted_images = extractor.extract_slides(\n",
    "    PPTX_PATH,\n",
    "    slide_numbers=slide_numbers,\n",
    ")\n",
    "\n",
    "print(f\"Extracted {len(extracted_images)} images\\n\")\n",
    "\n",
    "# Preview extracted images\n",
    "for slide_num, img_bytes, info in extracted_images:\n",
    "    print(f\"\\n--- Slide {slide_num} ---\")\n",
    "    print(f\"Image ID: {info.image_id}\")\n",
    "    print(f\"Type: {info.image_type}\")\n",
    "    print(f\"Size: {info.width_px}x{info.height_px} px ({info.size_bytes / 1024:.1f} KB)\")\n",
    "    \n",
    "    # Display image (scaled down for notebook)\n",
    "    display(IPImage(data=img_bytes, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Upload Images to S3\n",
    "\n",
    "Upload extracted images to your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 store\n",
    "store = S3ImageStore(\n",
    "    bucket=S3_BUCKET,\n",
    "    prefix=S3_PREFIX,\n",
    ")\n",
    "\n",
    "# Upload images\n",
    "print(\"Uploading images to S3...\\n\")\n",
    "\n",
    "s3_uris = []\n",
    "for slide_num, img_bytes, info in extracted_images:\n",
    "    try:\n",
    "        uri = store.upload_image(img_bytes, info)\n",
    "        s3_uris.append(uri)\n",
    "        print(f\"Slide {slide_num}: {uri}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Slide {slide_num}: FAILED - {e}\")\n",
    "\n",
    "print(f\"\\nUploaded {len(s3_uris)} images to S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Presigned URLs (for viewing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Presigned URLs (valid for 1 hour):\\n\")\n",
    "\n",
    "for uri in s3_uris:\n",
    "    try:\n",
    "        presigned_url = store.get_presigned_url(uri, expiration=3600)\n",
    "        print(f\"{uri}\")\n",
    "        print(f\"  -> {presigned_url[:80]}...\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"{uri}: Error generating URL - {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Store Mappings (Optional - requires OpenSearch)\n",
    "\n",
    "Store image-to-slide mappings in OpenSearch for integration with your RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this cell if you don't have OpenSearch configured\n",
    "\n",
    "if OPENSEARCH_ENDPOINT:\n",
    "    # Initialize mapper with your OpenSearch client\n",
    "    # Replace with your actual OpenSearch client initialization\n",
    "    from rag_assist.vectorstore.opensearch_client import OpenSearchClient\n",
    "    \n",
    "    os_client = OpenSearchClient(endpoint=OPENSEARCH_ENDPOINT)\n",
    "    mapper = ImageMapper(opensearch_client=os_client)\n",
    "    \n",
    "    # Update slide mappings with extracted image info\n",
    "    slide_to_info = {info.slide_number: info for _, _, info in extracted_images}\n",
    "    for mapping in slide_mappings:\n",
    "        if mapping.slide_number in slide_to_info:\n",
    "            mapping.images = [slide_to_info[mapping.slide_number]]\n",
    "    \n",
    "    # Store mappings\n",
    "    count = mapper.store_mappings(slide_mappings)\n",
    "    print(f\"Stored {count} mappings in OpenSearch\")\n",
    "else:\n",
    "    print(\"OpenSearch not configured. Skipping mapping storage.\")\n",
    "    print(\"Set OPENSEARCH_ENDPOINT in Cell 1 to enable this feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Demo: Retrieve Images for a Slide\n",
    "\n",
    "Demonstrate how to retrieve images given a slide number (simulating RAG retrieval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get document ID from extracted images\n",
    "if extracted_images:\n",
    "    doc_id = extracted_images[0][2].document_id\n",
    "    print(f\"Document ID: {doc_id}\\n\")\n",
    "    \n",
    "    # Simulate retrieval: given a slide number, find the image\n",
    "    test_slide_num = slide_numbers[0] if slide_numbers else 1\n",
    "    print(f\"Looking up images for slide {test_slide_num}...\\n\")\n",
    "    \n",
    "    # In production, this would query OpenSearch\n",
    "    # For demo, we use our local data\n",
    "    for slide_num, img_bytes, info in extracted_images:\n",
    "        if slide_num == test_slide_num:\n",
    "            print(f\"Found image: {info.s3_uri}\")\n",
    "            print(f\"Type: {info.image_type}\")\n",
    "            print(f\"\\nDisplaying image:\")\n",
    "            display(IPImage(data=img_bytes, width=500))\n",
    "            break\n",
    "else:\n",
    "    print(\"No images extracted. Run cells 5-6 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Full Pipeline (One Function Call)\n",
    "\n",
    "Run the complete extraction pipeline with a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full pipeline\n",
    "result = extract_images_from_pptx(\n",
    "    pptx_path=PPTX_PATH,\n",
    "    s3_bucket=S3_BUCKET,\n",
    "    s3_prefix=S3_PREFIX,\n",
    "    opensearch_client=None,  # Set to your client if using OpenSearch\n",
    "    store_mappings=False,    # Set to True if using OpenSearch\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"EXTRACTION RESULT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Document ID: {result.document_id}\")\n",
    "print(f\"Filename: {result.filename}\")\n",
    "print(f\"Total slides: {result.total_slides}\")\n",
    "print(f\"Slides with images: {result.slides_with_images}\")\n",
    "print(f\"Images extracted: {len(result.images)}\")\n",
    "print(f\"Errors: {len(result.errors)}\")\n",
    "\n",
    "if result.errors:\n",
    "    print(f\"\\nErrors encountered:\")\n",
    "    for error in result.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "print(f\"\\nExtracted images:\")\n",
    "for img in result.images:\n",
    "    print(f\"  Slide {img.slide_number}: {img.s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cleanup (Optional)\n",
    "\n",
    "Delete test images from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete uploaded images\n",
    "# WARNING: This will delete all images for this document from S3!\n",
    "\n",
    "# if extracted_images:\n",
    "#     doc_id = extracted_images[0][2].document_id\n",
    "#     deleted = store.delete_document_images(doc_id)\n",
    "#     print(f\"Deleted {deleted} images from S3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Detection**: `PPTXImageDetector` identifies slides with SmartArt, pictures, and charts\n",
    "2. **Extraction**: `PPTXImageExtractor` renders slides as PNG images\n",
    "3. **Storage**: `S3ImageStore` uploads images to S3 with structured paths\n",
    "4. **Mapping**: `ImageMapper` stores slide-to-image mappings in OpenSearch\n",
    "5. **Pipeline**: `extract_images_from_pptx()` runs the full workflow\n",
    "\n",
    "### Integration with RAG\n",
    "\n",
    "To integrate with your existing text-based RAG:\n",
    "\n",
    "```python\n",
    "# During retrieval, if a chunk has slide_number:\n",
    "chunk = retrieve_chunk(query)\n",
    "if chunk.metadata.slide_number:\n",
    "    images = mapper.get_s3_uris_for_slide(\n",
    "        document_id=chunk.metadata.document_id,\n",
    "        slide_number=chunk.metadata.slide_number\n",
    "    )\n",
    "    if images:\n",
    "        # Include image URLs in response\n",
    "        presigned_urls = [store.get_presigned_url(uri) for uri in images]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
